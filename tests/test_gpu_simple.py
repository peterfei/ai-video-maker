#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆGPUæ£€æµ‹è„šæœ¬
ä¸ä¾èµ–é¡¹ç›®é…ç½®ï¼Œç›´æ¥æµ‹è¯•PyTorchå’ŒMPS
"""

def main():
    print("=" * 60)
    print("ç®€åŒ–ç‰ˆ GPU æ£€æµ‹æµ‹è¯•")
    print("=" * 60)

    # 1. æ£€æµ‹PyTorch
    print("\n1. æ£€æµ‹ PyTorch...")
    try:
        import torch
        print(f"   âœ… PyTorch å·²å®‰è£…")
        print(f"   ç‰ˆæœ¬: {torch.__version__}")
    except ImportError:
        print(f"   âŒ PyTorch æœªå®‰è£…")
        print(f"   è¯·è¿è¡Œ: pip install torch")
        return

    # 2. æ£€æµ‹CUDA
    print("\n2. æ£€æµ‹ CUDA...")
    if torch.cuda.is_available():
        print(f"   âœ… CUDA å¯ç”¨")
        print(f"   è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"   è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")
    else:
        print(f"   âš ï¸  CUDA ä¸å¯ç”¨")

    # 3. æ£€æµ‹MPS (Apple Silicon)
    print("\n3. æ£€æµ‹ MPS (Apple Silicon)...")
    if hasattr(torch.backends, 'mps'):
        if torch.backends.mps.is_available():
            print(f"   âœ… MPS å¯ç”¨")
            print(f"   è¿™æ˜¯ Apple Silicon èŠ¯ç‰‡!")

            # å°è¯•åˆ›å»ºMPSè®¾å¤‡
            try:
                device = torch.device('mps')
                print(f"   MPS è®¾å¤‡: {device}")

                # æµ‹è¯•å¼ é‡åˆ›å»º
                test_tensor = torch.randn(100, 100, device=device)
                print(f"   âœ… æˆåŠŸåœ¨ MPS è®¾å¤‡ä¸Šåˆ›å»ºå¼ é‡")
                print(f"   æµ‹è¯•å¼ é‡å½¢çŠ¶: {test_tensor.shape}")

                # ç®€å•è®¡ç®—æµ‹è¯•
                result = test_tensor @ test_tensor.T
                print(f"   âœ… MPS çŸ©é˜µè¿ç®—æµ‹è¯•é€šè¿‡")

            except Exception as e:
                print(f"   âŒ MPS æµ‹è¯•å¤±è´¥: {e}")
        else:
            print(f"   âš ï¸  MPS ä¸å¯ç”¨")
            print(f"   å¯èƒ½åŸå› :")
            print(f"   - ä¸æ˜¯ Apple Silicon èŠ¯ç‰‡")
            print(f"   - macOS ç‰ˆæœ¬è¿‡ä½")
            print(f"   - PyTorch ç‰ˆæœ¬ä¸æ”¯æŒ MPS")
    else:
        print(f"   âš ï¸  torch.backends.mps ä¸å­˜åœ¨")
        print(f"   è¯·æ›´æ–°åˆ° PyTorch 2.0+")

    # 4. æ£€æµ‹èŠ¯ç‰‡å‹å·
    print("\n4. æ£€æµ‹èŠ¯ç‰‡å‹å·...")
    try:
        import subprocess
        import platform

        if platform.system() == 'Darwin':
            result = subprocess.run(['sysctl', 'machdep.cpu.brand_string'],
                                  capture_output=True, text=True, timeout=5)
            cpu_brand = result.stdout.strip()
            print(f"   CPU: {cpu_brand}")

            if 'Apple' in cpu_brand:
                if 'M4' in cpu_brand:
                    print(f"   ğŸ‰ æ£€æµ‹åˆ° Apple M4 èŠ¯ç‰‡!")
                    if 'Max' in cpu_brand:
                        print(f"   å‹å·: M4 Max (40æ ¸GPU)")
                    elif 'Pro' in cpu_brand:
                        print(f"   å‹å·: M4 Pro (20æ ¸GPU)")
                    else:
                        print(f"   å‹å·: M4 åŸºç¡€ç‰ˆ (10æ ¸GPU)")
                elif 'M3' in cpu_brand:
                    print(f"   ğŸ‰ æ£€æµ‹åˆ° Apple M3 èŠ¯ç‰‡!")
                elif 'M2' in cpu_brand:
                    print(f"   ğŸ‰ æ£€æµ‹åˆ° Apple M2 èŠ¯ç‰‡!")
                elif 'M1' in cpu_brand:
                    print(f"   ğŸ‰ æ£€æµ‹åˆ° Apple M1 èŠ¯ç‰‡!")
        else:
            print(f"   å¹³å°: {platform.system()}")

    except Exception as e:
        print(f"   âš ï¸  æ— æ³•æ£€æµ‹èŠ¯ç‰‡å‹å·: {e}")

    # 5. ç³»ç»Ÿå†…å­˜
    print("\n5. ç³»ç»Ÿå†…å­˜...")
    try:
        import psutil
        vm = psutil.virtual_memory()
        print(f"   æ€»å†…å­˜: {vm.total / (1024**3):.1f} GB")
        print(f"   å¯ç”¨å†…å­˜: {vm.available / (1024**3):.1f} GB")
        print(f"   ä½¿ç”¨ç‡: {vm.percent}%")
    except ImportError:
        print(f"   âš ï¸  psutil æœªå®‰è£…ï¼Œæ— æ³•è·å–å†…å­˜ä¿¡æ¯")
    except Exception as e:
        print(f"   âš ï¸  è·å–å†…å­˜ä¿¡æ¯å¤±è´¥: {e}")

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("æ£€æµ‹æ€»ç»“:")

    has_gpu = False
    if torch.cuda.is_available():
        print("âœ… NVIDIA GPU (CUDA) å¯ç”¨ - è§†é¢‘æ¸²æŸ“å°†ä½¿ç”¨ GPU åŠ é€Ÿ")
        has_gpu = True
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print("âœ… Apple Silicon GPU (MPS) å¯ç”¨ - è§†é¢‘æ¸²æŸ“å°†ä½¿ç”¨ GPU åŠ é€Ÿ")
        has_gpu = True

    if not has_gpu:
        print("âš ï¸  GPU åŠ é€Ÿä¸å¯ç”¨ - å°†ä½¿ç”¨ CPU å¤„ç†")

    print("=" * 60)

if __name__ == "__main__":
    main()
